{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "84633162",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import platform\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "from pupil_apriltags import Detector\n",
    "import open3d as o3d\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import collections\n",
    "import k3d\n",
    "from PoseEstimation.Mesh_Matcher import *\n",
    "from PoseEstimation.Colmap_Reader import *\n",
    "from PoseEstimation.Apriltag_Colmap import *\n",
    "from PoseEstimation.GT_Extration import rigid_transform_3D\n",
    "import trimesh\n",
    "import pyrender\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3976cf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "a2d2 = [[-3.738231 ,-0.731755 ,-0.328742],\n",
    "    [-2.637552 ,-0.291120 ,-2.638498],\n",
    "    [0.646090 ,-0.735447 ,-0.999240],\n",
    "    [-0.068454 ,-1.510249 ,2.817723],\n",
    "    [-3.638991 ,-0.949203 ,1.054112],\n",
    "    [-1.450608 ,-0.856347 ,0.655611]]\n",
    "\n",
    "a2d1 = [[-0.463405 ,-0.737901 ,3.250370],\n",
    "       [-2.756239 ,-0.312765 ,2.103297],\n",
    "       [-1.103867 ,-0.729082 ,-1.151607],\n",
    "       [2.675915 ,-1.559122 ,-0.357202],\n",
    "       [0.901114 ,-0.947988 ,3.181215],\n",
    "       [0.618660 ,-0.928016 ,0.953832]]\n",
    "\n",
    "a1d1 = [[3.176764, -0.743093 ,0.347837],\n",
    "       [1.207308 ,-0.537581 ,3.230441],\n",
    "       [-1.180794, -0.635370 ,1.481291],\n",
    "       [-1.357942, -1.557935 ,-0.596481],\n",
    "       [1.503481 ,-1.525294, -3.660501],\n",
    "       [0.554387 ,-0.842245 ,-0.227942]]\n",
    "\n",
    "a1d2 = [[-2.751245, -0.733777 ,-0.333212],\n",
    "       [-0.531045 ,-0.543927 ,-2.986102],\n",
    "       [1.695879 ,-0.656546 ,-0.978193],\n",
    "       [1.536978 ,-1.557403 ,1.012150],\n",
    "       [-1.503375 ,-1.568758 ,3.784639],\n",
    "       [-0.193254 ,-0.846000 ,0.419316]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ead08ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import pi\n",
    "def position_error(T_e, T_gt):\n",
    "\n",
    "    return np.linalg.norm(T_e- T_gt)\n",
    "\n",
    "\n",
    "def rotation_error(R_e, R_gt):\n",
    "    \n",
    "    return (180/pi) * np.arccos((np.trace(np.matmul(R_e, R_gt.T))-1)/2)\n",
    "\n",
    "def draw_registration_result(source, target, transformation, colored = True):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    if colored:\n",
    "        source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "        target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp])\n",
    "\n",
    "def qvec2rotmat(qvec):\n",
    "    return np.array([\n",
    "        [1 - 2 * qvec[2]**2 - 2 * qvec[3]**2,\n",
    "         2 * qvec[1] * qvec[2] - 2 * qvec[0] * qvec[3],\n",
    "         2 * qvec[3] * qvec[1] + 2 * qvec[0] * qvec[2]],\n",
    "        [2 * qvec[1] * qvec[2] + 2 * qvec[0] * qvec[3],\n",
    "         1 - 2 * qvec[1]**2 - 2 * qvec[3]**2,\n",
    "         2 * qvec[2] * qvec[3] - 2 * qvec[0] * qvec[1]],\n",
    "        [2 * qvec[3] * qvec[1] - 2 * qvec[0] * qvec[2],\n",
    "         2 * qvec[2] * qvec[3] + 2 * qvec[0] * qvec[1],\n",
    "         1 - 2 * qvec[1]**2 - 2 * qvec[2]**2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38ac1001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k3d_frustrum(pose, name, size=0.009, color=0x0000ff):\n",
    "    # i.e. not using image sizes \n",
    "    pos = pose[:3, 3]\n",
    "    \n",
    "    forward = -pose[:3, 2] * size * -1.4\n",
    "    right = -pose[:3, 0] * size * 1.25\n",
    "    up = -pose[:3, 1] * size\n",
    "    \n",
    "    #verts = [pos, pos + forward*size ]\n",
    "    verts = [pos, pos + forward - right*0.5 + up*0.5, pos + forward + right * 0.5 + up * 0.5, pos ]\n",
    "    verts += [pos, pos + forward - right*0.5 - up*0.5, pos + forward + right * 0.5 - up * 0.5, pos ]\n",
    "    verts += [pos, pos + forward - right*0.5 + up*0.5, pos + forward - right * 0.5 - up * 0.5, pos]\n",
    "    verts += [pos, pos + forward + right*0.5 + up*0.5, pos + forward + right * 0.5 - up * 0.5, pos]\n",
    "    return k3d.line(verts, color=color, width=2.5, name = name, shader=\"simple\")\n",
    "\n",
    "def visualization_registration(reg, mesh):\n",
    "    vertices = [ ]\n",
    "\n",
    "    frustrums = []\n",
    "\n",
    "    colors = [0xff0000, 0x00ff00, 0x0000ff, 0xffcc00, 0xccff00, 0x00ccff]\n",
    "\n",
    "    for i, frame in enumerate(reg.keys()):\n",
    "        pos = reg[frame][:3, 3] \n",
    "        vertices += pos.tolist()\n",
    "        frustrums.append( k3d_frustrum(reg[frame], name = str(frame), size=0.1, color=colors[i % len(colors)]) )\n",
    "\n",
    "    vertices = np.array(vertices)\n",
    "\n",
    "    lines = k3d.line(vertices, color=0xff0000, width=2.5, shader=\"simple\") # + line\n",
    "    pts = k3d.points(vertices, point_size=0.003)\n",
    "\n",
    "    plot3d = k3d.plot(antialias=True, camera_auto_fit=True)\n",
    "\n",
    "    #plot3d += lines\n",
    "    plot3d += pts \n",
    "\n",
    "    for f in frustrums:\n",
    "        plot3d += f\n",
    "\n",
    "    plot3d += k3d.points( [vertices[:3]], point_size=0.0075, color=0x00ff00)\n",
    "\n",
    "    plot3d += k3d.mesh(np.array(mesh.vertices), np.array(mesh.triangles).flatten(), color=0xffcc00)\n",
    "    plot3d.display()\n",
    "\n",
    "\n",
    "def visualization_PI_IPhone(gt, reg,  mesh):\n",
    "    vertices = [ ]\n",
    "\n",
    "    frustrums = []\n",
    "\n",
    "    colors = [0xff0000, 0x00ff00]\n",
    "\n",
    "    for frame in reg.keys():\n",
    "        est_pose = reg[frame][:3, 3]\n",
    "        gt_pose = gt[frame][:3, 3]\n",
    " \n",
    "        vertices += est_pose.tolist()\n",
    "        vertices += gt_pose.tolist()\n",
    "        frustrums.append( k3d_frustrum(reg[frame], name = str(frame) + \"_GT\", size=0.1, color=colors[0]) )\n",
    "        frustrums.append( k3d_frustrum(gt[frame], name = str(frame)+ \"Est\", size=0.1, color=colors[1]) )\n",
    "\n",
    "    vertices = np.array(vertices)\n",
    "\n",
    "    lines = k3d.line(vertices, color=0xff0000, width=2.5, shader=\"simple\") # + line\n",
    "    pts = k3d.points(vertices, point_size=0.003)\n",
    "\n",
    "    plot3d = k3d.plot(antialias=True, camera_auto_fit=True)\n",
    "\n",
    "    #plot3d += lines\n",
    "    plot3d += pts \n",
    "\n",
    "    for f in frustrums:\n",
    "        plot3d += f\n",
    "\n",
    "    plot3d += k3d.points( [vertices[:3]], point_size=0.0075, color=0x00ff00)\n",
    "\n",
    "    plot3d += k3d.mesh(np.array(mesh.vertices), np.array(mesh.triangles).flatten(), color=0xffcc00)\n",
    "    plot3d.display()\n",
    "\n",
    "\n",
    "at_detector = Detector(\n",
    "            families=\"tagStandard41h12\",\n",
    "            nthreads=1,\n",
    "            quad_decimate=1.0,\n",
    "            quad_sigma=0.0,\n",
    "            refine_edges=1,\n",
    "            decode_sharpening=0.25,\n",
    "            debug=0,\n",
    "        )\n",
    "\n",
    "\n",
    "Register = collections.namedtuple(\n",
    "    \"RegisterInfo\", [\"CameraPose\", \"Intrinsic\", \"TagPose\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "898bf8c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if platform == \"linux\" or platform == \"linux2\":  \n",
    "# linux\n",
    "    dataset_path = r\"/home/biyang/Documents/3D_Gaze/dataset/PupilInvisible/office1/data_1/images_undistorted\"\n",
    "    database_path = r\"/home/biyang/Documents/3D_Gaze/dataset/PupilInvisible/office1/data_1/colmap_sparser\"\n",
    "    mesh_fullpath = r\"/home/biyang/Documents/3D_Gaze/dataset/3D_scanner_app/Apriltag1_dataset1/data3d/textured_output.obj\"\n",
    "    #keypoints_gt = np.array(a1d2)\n",
    "elif platform == \"win32\":\n",
    "# Windows...\n",
    "    # dataset_path = r\"D:\\Documents\\Semester_Project\\3D_Gaze\\dataset\\3D_Scanner_App\\Apriltag1_dataset1\\frames\"\n",
    "    # database_path = r\"D:\\Documents\\Semester_Project\\3D_Gaze\\dataset\\3D_Scanner_App\\Apriltag1_dataset1\\colmap_reconstruction\"\n",
    "\n",
    "    dataset_path = r\"D:\\Documents\\Semester_Project\\3D_Gaze\\dataset\\PupilInvisible\\office1\\data_1\\images_undistorted\"\n",
    "    database_path = r\"D:\\Documents\\Semester_Project\\3D_Gaze\\dataset\\PupilInvisible\\office1\\data_1\\colmap_sparser\"\n",
    "    mesh_fullpath = r\"D:\\Documents\\Semester_Project\\3D_Gaze\\dataset\\3D_Scanner_App\\Apriltag1_dataset1\\data3d\\textured_output.obj\"\n",
    "    \n",
    "    \n",
    "VISUALIZATION_3D = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "605973af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected model format: '.bin'\n",
      "Detected model format: '.bin'\n"
     ]
    }
   ],
   "source": [
    "database_colmap = ColmapReader(database_path)\n",
    "cameras, images, points3D = database_colmap.read_sparse_model()\n",
    "pcd_reconstruction, _= database_colmap.read_dense_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7ac9eff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:180: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 3 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 3 tags in the frame\n",
      "There are totally 3 tags in the frame\n",
      "There are totally 3 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 3 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 3 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 3 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 3 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 3 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 2 tags in the frame\n"
     ]
    }
   ],
   "source": [
    "registered_3d_points_xyz = {} # register for each tag (including only xyz)\n",
    "registered_3d_points_info = {} # register for each tag (including other info)\n",
    "registered_3d_points_repro_error = {} # register for each tag (including other info)\n",
    "visited_id = []\n",
    "for frame in images.values():\n",
    "\n",
    "    img_fullpath = os.path.join(dataset_path, frame.name)\n",
    "    img = cv2.imread(img_fullpath, cv2.IMREAD_GRAYSCALE)\n",
    "    tags = at_detector.detect(img)\n",
    "    if len(tags) == 0:\n",
    "        continue\n",
    "\n",
    "    tag_ids = [tag.tag_id for tag in tags]\n",
    "    masks = get_mask(img_grayscale=img, tags=tags, visualization=False)\n",
    "\n",
    "    # Find the corresponding 3d points\n",
    "    search_space_pixels = np.array(frame.xys.astype(int))\n",
    "    points_3d = frame.point3D_ids\n",
    "    corresponding_3d_ids, _ = get_corresponding_3d_points_ids(masks, search_space_pixels, points_3d)\n",
    "\n",
    "    # filter the duplicated ids\n",
    "    for (tag_id, corresponding_3d_id) in zip(tag_ids, corresponding_3d_ids):\n",
    "        non_visited_3d_id = filter_array(corresponding_3d_id, visited_id)\n",
    "        non_visited_3d_id = list(non_visited_3d_id)\n",
    "        visited_id.extend(non_visited_3d_id)\n",
    "\n",
    "        corresponding_3d_xyz, corresponding_3d_repro_error, corresponding_3d_info = get_valid_3d_points(non_visited_3d_id, points3D)\n",
    "\n",
    "        if len(corresponding_3d_xyz) == 0:\n",
    "            continue\n",
    "        if tag_id not in registered_3d_points_xyz.keys():\n",
    "            registered_3d_points_xyz[tag_id] = corresponding_3d_xyz\n",
    "            registered_3d_points_info[tag_id] = corresponding_3d_info\n",
    "            registered_3d_points_repro_error[tag_id] = corresponding_3d_repro_error\n",
    "\n",
    "        else:\n",
    "            registered_3d_points_xyz[tag_id] = np.concatenate((registered_3d_points_xyz[tag_id], corresponding_3d_xyz), axis=0)\n",
    "            registered_3d_points_info[tag_id] = np.concatenate((registered_3d_points_info[tag_id], corresponding_3d_info), axis=0)\n",
    "            registered_3d_points_repro_error[tag_id] = np.concatenate((registered_3d_points_repro_error[tag_id], corresponding_3d_repro_error), axis=0)\n",
    "\n",
    "\n",
    "# with open(r\"D:\\Documents\\Semester_Project\\3D_Gaze\\dataset\\PupilInvisible\\room1\\apriltags_repro_error.json\", \"w\") as outfile:\n",
    "#    json.dump({k: v.tolist() for k, v in registered_3d_points_repro_error.items()}, outfile, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1621f5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6159682487356248\n",
      "[0] [10] 3\n"
     ]
    }
   ],
   "source": [
    "filtered_registered_tag_points_xyz, outliers_xyz = filter_registered_points(registered_3d_points_xyz, registered_3d_points_repro_error)\n",
    "\n",
    "keypoints_rc = []\n",
    "for points in filtered_registered_tag_points_xyz.values():\n",
    "    keypoints_rc.append(np.mean(points, axis = 0))\n",
    "keypoints_rc = np.array(keypoints_rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "d1caf163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5292238029690113\n"
     ]
    }
   ],
   "source": [
    "# keypoints_gt = np.array(a1d1)\n",
    "# dist_gt = np.linalg.norm(keypoints_gt[-1] - keypoints_gt[1])\n",
    "# dist_rc = np.linalg.norm(keypoints_rc[0] - keypoints_rc[1])\n",
    "\n",
    "# print(dist_gt/dist_rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cd8cd76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: Das Handle ist ungültig. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: Das Handle ist ungültig. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: Der angeforderte Transformationsvorgang wird nicht unterstützt. \n"
     ]
    }
   ],
   "source": [
    "pcd_copy = copy.deepcopy(pcd_reconstruction)\n",
    "pcd_copy.paint_uniform_color(np.array([220, 220 ,220])/255)\n",
    "\n",
    "\n",
    "# for tag in registered_3d_points_info.keys():\n",
    "#     for info in registered_3d_points_info[tag]:\n",
    "#         print(info.error)\n",
    "    #visualization_3d(pcd_rc, registered_3d_points_xyz, highlight=False)\n",
    "\n",
    "pcd_outliers = create_pcd(outliers_xyz, color = [0, 0 ,0])\n",
    "vis = [pcd_copy, pcd_outliers]\n",
    "for i, tag_id in enumerate(filtered_registered_tag_points_xyz.keys()):\n",
    "\n",
    "    pcd_tag = create_geometry_at_points(filtered_registered_tag_points_xyz[tag_id], colorbar[i], radius = 0.1)\n",
    "    vis.append(pcd_tag)\n",
    "\n",
    "o3d.visualization.draw_geometries(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51cec33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keypoints_gt = np.flip(keypoints_gt, 0)\n",
    "keypoints_gt = np.array(a1d1)\n",
    "mesh_gt = o3d.io.read_triangle_mesh(mesh_fullpath)\n",
    "num_points = 30000\n",
    "pcd_gt = mesh_gt.sample_points_uniformly(num_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b76cffa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_opt, R_opt,t_opt = rigid_transform_3D(np.asmatrix(keypoints_gt), np.asmatrix(keypoints_rc), True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3f9d6293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7044136361881836\n"
     ]
    }
   ],
   "source": [
    "s_opt = s_opt /1\n",
    "print(s_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "6c969346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s_opt = 0.5292238029690113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "68882d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: Der angeforderte Transformationsvorgang wird nicht unterstützt. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: Das Handle ist ungültig. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: Der angeforderte Transformationsvorgang wird nicht unterstützt. \n"
     ]
    }
   ],
   "source": [
    "# est_extrinsic = np.concatenate(\n",
    "#                     [np.concatenate([R_opt, t_opt.reshape(3, 1)], axis=1), np.array([[0, 0, 0, 1]])], axis=0)\n",
    "\n",
    "# pcd_gt= o3d.geometry.PointCloud()\n",
    "# pcd_gt.points = o3d.utility.Vector3dVector(keypoints_gt)\n",
    "\n",
    "# pcd_rc= o3d.geometry.PointCloud()\n",
    "# pcd_rc.points = o3d.utility.Vector3dVector(keypoints_rc)\n",
    "\n",
    "# pcd_rc.scale(s_opt ,center=np.zeros(3))\n",
    "\n",
    "# draw_registration_result(pcd_rc, pcd_gt, est_extrinsic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0030f0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical oulier removal\n",
      "Statistical oulier removal\n",
      "Statistical oulier removal\n",
      ":: Normalize point clouds\n",
      ":: Downsample with a voxel size 0.030.\n",
      "4758\n",
      ":: Estimate normal with search radius 0.060.\n",
      ":: Compute FPFH feature with search radius 0.150.\n",
      ":: Downsample with a voxel size 0.030.\n",
      "4887\n",
      ":: Estimate normal with search radius 0.060.\n",
      ":: Compute FPFH feature with search radius 0.150.\n",
      ":: RANSAC registration on downsampled point clouds.\n",
      "   Since the downsampling voxel size is 0.030,\n",
      "   we use a liberal distance threshold 0.045.\n",
      "3. Colored point cloud registration\n",
      "[2000, 0.02, 0]\n",
      "3-1. Downsample with a voxel size 0.02\n",
      "3-2. Estimate normal.\n",
      "3-3. Applying colored point cloud registration\n",
      "[1000, 0.01, 1]\n",
      "3-1. Downsample with a voxel size 0.01\n",
      "3-2. Estimate normal.\n",
      "3-3. Applying colored point cloud registration\n",
      "[200, 0.005, 2]\n",
      "3-1. Downsample with a voxel size 0.01\n",
      "3-2. Estimate normal.\n",
      "3-3. Applying colored point cloud registration\n"
     ]
    }
   ],
   "source": [
    "Aligner = MeshAlignment(pcd_reconstruction, pcd_gt, 30000, scale_factor = s_opt, PCD = True, filtering = True,voxel_size=0.03, icp_method=\"multiscale\")\n",
    "Aligner.register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5e572ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to recorver the translation because the point cloud we used in aligner is normalized and prescaled.\n",
    "# Rotation is not affected by those factors\n",
    "delta_tran = Aligner.centroid_gt - Aligner.result_icp.transformation[:3, :3] @ (Aligner.centroid_rc * Aligner.scale_factor)\n",
    "tran_new = Aligner.result_icp.transformation[:3, 3].reshape(3, 1) * Aligner.backward_factor + delta_tran.reshape(3, 1)\n",
    "est_new = np.concatenate(\n",
    "                    [np.concatenate([Aligner.result_icp.transformation[:3, :3], tran_new], axis=1), np.array([[0, 0, 0, 1]])], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d62915c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd_reconstruction_vis = copy.deepcopy(pcd_reconstruction)\n",
    "pcd_reconstruction_vis.scale(s_opt, center = np.zeros(3))\n",
    "Aligner.draw_registration_result(pcd_reconstruction_vis, mesh_gt, est_new, colored=True, inverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "647ed9c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207\n"
     ]
    }
   ],
   "source": [
    "PI_registration = {}\n",
    "for i, image_id in enumerate(images):\n",
    "    if i % 2!=0:\n",
    "        continue\n",
    "    image = images[image_id]\n",
    "    \n",
    "    rot = qvec2rotmat(image.qvec)\n",
    "    colmap_world2cam = np.concatenate(\n",
    "                    [np.concatenate([rot, image.tvec.reshape(3,1)], axis=1), np.array([[0, 0, 0, 1]])], axis=0)\n",
    "\n",
    "    register_result = est_new @ np.linalg.inv(colmap_world2cam)\n",
    "    register_result[:3, 3] = register_result[:3, 3] * s_opt\n",
    "    \n",
    "\n",
    "    PI_registration[image.name] = register_result\n",
    "\n",
    "\n",
    "print(len(PI_registration.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "df8d6cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"/home/biyang/Documents/3D_Gaze/dataset/PupilInvisible/office1/data_1/result_colmap.json\", \"w\") as outfile:\n",
    "    json.dump({k: v.tolist() for k, v in PI_registration.items()}, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ff1a25a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85ed011d2725409a94c2233ead870d62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualization_registration(PI_registration, mesh_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1ccbeaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"/home/biyang/Documents/3D_Gaze/dataset/PupilInvisible/office1/data_1/result_colmap.json\", \"r\") as f:\n",
    "    PI_registration = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9612e20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "XXX: resource creation failed\n",
      "XXX: resource creation failed\n"
     ]
    },
    {
     "ename": "GLError",
     "evalue": "GLError(\n\terr = 1285,\n\tdescription = b'out of memory',\n\tbaseOperation = glGenerateMipmap,\n\tcArguments = (GL_TEXTURE_2D,)\n)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGLError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[0;32mIn [90]\u001b[0m, in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m scene\u001b[38;5;241m.\u001b[39madd(light, pose\u001b[38;5;241m=\u001b[39mcamera_pose)\n\u001b[1;32m     30\u001b[0m r \u001b[38;5;241m=\u001b[39m pyrender\u001b[38;5;241m.\u001b[39mOffscreenRenderer(img_width, img_height)\n\u001b[0;32m---> 31\u001b[0m color, depth \u001b[38;5;241m=\u001b[39m \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscene\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# plt.figure()\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# plt.subplot(1,2,1)\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# plt.axis('off')\u001b[39;00m\n\u001b[1;32m     35\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(color)\n",
      "File \u001b[0;32m~/anaconda3/envs/sp2/lib/python3.8/site-packages/pyrender/offscreen.py:102\u001b[0m, in \u001b[0;36mOffscreenRenderer.render\u001b[0;34m(self, scene, flags, seg_node_map)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_platform\u001b[38;5;241m.\u001b[39msupports_framebuffers():\n\u001b[1;32m    101\u001b[0m     flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m RenderFlags\u001b[38;5;241m.\u001b[39mOFFSCREEN\n\u001b[0;32m--> 102\u001b[0m     retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_renderer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscene\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseg_node_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_renderer\u001b[38;5;241m.\u001b[39mrender(scene, flags, seg_node_map)\n",
      "File \u001b[0;32m~/anaconda3/envs/sp2/lib/python3.8/site-packages/pyrender/renderer.py:125\u001b[0m, in \u001b[0;36mRenderer.render\u001b[0;34m(self, scene, flags, seg_node_map)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m\"\"\"Render a scene with the given set of flags.\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;124;03m    in linear units.\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# Update context with meshes and textures\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscene\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m# Render necessary shadow maps\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(flags \u001b[38;5;241m&\u001b[39m RenderFlags\u001b[38;5;241m.\u001b[39mDEPTH_ONLY \u001b[38;5;129;01mor\u001b[39;00m flags \u001b[38;5;241m&\u001b[39m RenderFlags\u001b[38;5;241m.\u001b[39mSEG):\n",
      "File \u001b[0;32m~/anaconda3/envs/sp2/lib/python3.8/site-packages/pyrender/renderer.py:755\u001b[0m, in \u001b[0;36mRenderer._update_context\u001b[0;34m(self, scene, flags)\u001b[0m\n\u001b[1;32m    753\u001b[0m \u001b[38;5;66;03m# Add new textures to context\u001b[39;00m\n\u001b[1;32m    754\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m texture \u001b[38;5;129;01min\u001b[39;00m mesh_textures \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mesh_textures:\n\u001b[0;32m--> 755\u001b[0m     \u001b[43mtexture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_add_to_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    757\u001b[0m \u001b[38;5;66;03m# Remove old textures from context\u001b[39;00m\n\u001b[1;32m    758\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m texture \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mesh_textures \u001b[38;5;241m-\u001b[39m mesh_textures:\n",
      "File \u001b[0;32m~/anaconda3/envs/sp2/lib/python3.8/site-packages/pyrender/texture.py:202\u001b[0m, in \u001b[0;36mTexture._add_to_context\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m glTexImage2D(\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtex_type, \u001b[38;5;241m0\u001b[39m, fmt, width, height, \u001b[38;5;241m0\u001b[39m, fmt,\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_format, data\n\u001b[1;32m    200\u001b[0m )\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 202\u001b[0m     \u001b[43mglGenerateMipmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtex_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampler\u001b[38;5;241m.\u001b[39mmagFilter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    205\u001b[0m     glTexParameteri(\n\u001b[1;32m    206\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtex_type, GL_TEXTURE_MAG_FILTER, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampler\u001b[38;5;241m.\u001b[39mmagFilter\n\u001b[1;32m    207\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/sp2/lib/python3.8/site-packages/OpenGL/platform/baseplatform.py:402\u001b[0m, in \u001b[0;36m_NullFunctionPointer.__call__\u001b[0;34m(self, *args, **named)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m( \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnamed ):\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload():\n\u001b[0;32m--> 402\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnamed\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mOpenGL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m error\n",
      "File \u001b[0;32m~/anaconda3/envs/sp2/lib/python3.8/site-packages/OpenGL/error.py:228\u001b[0m, in \u001b[0;36m_ErrorChecker.glCheckError\u001b[0;34m(self, result, baseOperation, cArguments, *args)\u001b[0m\n\u001b[1;32m    226\u001b[0m err \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_currentChecker()\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m err \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_noErrorResult:\n\u001b[0;32m--> 228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m GLError(\n\u001b[1;32m    229\u001b[0m         err,\n\u001b[1;32m    230\u001b[0m         result,\n\u001b[1;32m    231\u001b[0m         cArguments \u001b[38;5;241m=\u001b[39m cArguments,\n\u001b[1;32m    232\u001b[0m         baseOperation \u001b[38;5;241m=\u001b[39m baseOperation,\n\u001b[1;32m    233\u001b[0m     )\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31m<class 'str'>\u001b[0m: (<class 'KeyboardInterrupt'>, KeyboardInterrupt())"
     ]
    }
   ],
   "source": [
    "\n",
    "mesh_trimesh = trimesh.load(\"/home/biyang/Documents/3D_Gaze/dataset/3D_scanner_app/Apriltag1_dataset1/data3d/textured_output.obj\")\n",
    "im = Image.open(r\"/home/biyang/Documents/3D_Gaze/dataset/3D_scanner_app/Apriltag1_dataset1/data3d/textured_output.jpg\")\n",
    "#tex = trimesh.visual.TextureVisuals(image=im)\n",
    "#print(mesh_trimesh.visual.uv)\n",
    "#mesh_trimesh.visual.texture = tex\n",
    "color = trimesh.visual.uv_to_color(mesh_trimesh.visual.uv, im)\n",
    "mesh_trimesh.visual.color = color\n",
    "\n",
    "camera_pose = np.array(PI_registration['00011.jpg'])\n",
    "mesh = pyrender.Mesh.from_trimesh(mesh_trimesh)\n",
    "scene = pyrender.Scene()\n",
    "scene.add(mesh)\n",
    "# pyrender.Viewer(scene, use_raymond_lighting=True)\n",
    "\n",
    "\n",
    "camera = pyrender.PerspectiveCamera(yfov=np.pi / 3.0, aspectRatio=1.0)\n",
    "s = np.sqrt(2)/2\n",
    "\n",
    "\n",
    "PI_intrinsics = np.array([[766.2927454396544, 0.0, 543.6272327745995],\n",
    "                                [0.0, 766.3976103393867, 566.0580149497666],\n",
    "                                [0.0, 0.0, 1.0]])\n",
    "\n",
    "img_width = 1088\n",
    "img_height = 1080\n",
    "\n",
    "scene.add(camera, pose=camera_pose)\n",
    "light = pyrender.DirectionalLight(color=np.ones(3), intensity=3.0)\n",
    "scene.add(light, pose=camera_pose)\n",
    "r = pyrender.OffscreenRenderer(img_width, img_height)\n",
    "color, depth = r.render(scene)\n",
    "# plt.figure()\n",
    "# plt.subplot(1,2,1)\n",
    "# plt.axis('off')\n",
    "plt.imshow(color)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "abadb892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117\n",
      "117\n"
     ]
    }
   ],
   "source": [
    "IPhone_registration = {}\n",
    "IPhone_GT = {}\n",
    "pose_path = r\"D:\\Documents\\Semester_Project\\3D_Gaze\\dataset\\3D_Scanner_App\\Apriltag1_dataset1\\pose\"\n",
    "r = R.from_euler('xyz', [0, 180, 180], degrees=True)\n",
    "Additional_Rotation = r.as_matrix()\n",
    "\n",
    "additional_rotation = np.concatenate(\n",
    "                [np.concatenate([Additional_Rotation, np.zeros((3,1))], axis=1), np.array([[0, 0, 0, 1]])], axis=0)\n",
    "\n",
    "for i, image_id in enumerate(images):\n",
    "    # if i % 20!=0:\n",
    "    #     continue\n",
    "    image = images[image_id]\n",
    "    json_name = image.name.replace('jpg', 'json')\n",
    "\n",
    "    with open(os.path.join(pose_path, json_name), 'r') as f:\n",
    "        camera_param = json.load(f)\n",
    "\n",
    "    ext_gt =  np.array(camera_param[\"cameraPoseARFrame\"]).reshape(4, 4)  @ additional_rotation\n",
    "\n",
    "    \n",
    "    rot = qvec2rotmat(image.qvec)\n",
    "    colmap_world2cam = np.concatenate(\n",
    "                    [np.concatenate([rot, image.tvec.reshape(3,1)], axis=1), np.array([[0, 0, 0, 1]])], axis=0)\n",
    "\n",
    "    register_result = est_new @ np.linalg.inv(colmap_world2cam)\n",
    "    register_result[:3, 3] = register_result[:3, 3] * s_opt\n",
    "    \n",
    "\n",
    "    IPhone_registration[image.name] = register_result\n",
    "    IPhone_GT[image.name] = ext_gt\n",
    "\n",
    "\n",
    "print(len(IPhone_registration.keys()))\n",
    "print(len(IPhone_GT.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "dd0e203f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\ybMas\\anaconda3\\envs\\apriltag\\lib\\site-packages\\traittypes\\traittypes.py:101: UserWarning: Given trait value dtype \"float64\" does not match required type \"float32\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n",
      "d:\\Users\\ybMas\\anaconda3\\envs\\apriltag\\lib\\site-packages\\traittypes\\traittypes.py:101: UserWarning: Given trait value dtype \"int32\" does not match required type \"uint32\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26bf9f9525ab4c449254f7c4ff072ed9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualization_PI_IPhone(IPhone_GT, IPhone_registration ,  mesh_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "11fa2fb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.91805858, -0.3806811 ,  0.11068129,  0.21480709],\n",
       "       [ 0.35735638, -0.9155172 , -0.18472863, -0.50719932],\n",
       "       [ 0.17165333, -0.13003904,  0.97653724, -3.05254395],\n",
       "       [ 0.        ,  0.        ,  0.        ,  1.        ]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PI_registration[\"01321.jpg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "9aaddf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_error = []\n",
    "rot_error = []\n",
    "for gt_pose, est_pose in zip(IPhone_registration.values(), IPhone_GT.values()):\n",
    "    pos_error.append(position_error(est_pose[:3, 3], gt_pose[:3, 3]))\n",
    "    rot_error.append(rotation_error(est_pose[:3, :3], gt_pose[:3, :3]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "4d607696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1168391553520796, 0.11105689632457016, 0.10565543176618353, 0.11369112382740497, 0.10973845592075394, 0.09727571279680233, 0.09632918527710187, 0.12549694224545482, 0.10379231045965384, 0.1152914080353012, 0.10368661493530491, 0.08762490125973327, 0.12574400416145629, 0.08486749591815809, 0.02945901380954329, 0.07123032770907399, 0.1053684599047804, 0.07434248816256814, 0.028237349526207357, 0.06728009910574874, 0.08162667907282056, 0.052612637376784725, 0.07245569065933723, 0.052166608203055874, 0.05834690315983716, 0.05292690590008789, 0.03734074723802894, 0.04797835684498888, 0.06192995016585236, 0.035727758894619766, 0.052482431374834715, 0.027066631222303125, 0.04726231406153163, 0.03330210861562493, 0.02922191260804831, 0.0326979449550595, 0.018446319331848576, 0.039204924760694176, 0.022668713806235325, 0.019333043617062867, 0.036084522467467114, 0.03182772003618028, 0.022105030179333674, 0.040191005565892154, 0.023956478670535485, 0.02572653729499393, 0.030110184994963603, 0.03243990643162524, 0.0930952086718033, 0.03518612309424529, 0.03964050553037191, 0.07360804856185751, 0.05098184376624156, 0.03108518052394701, 0.03474510302770974, 0.03378926754816458, 0.037190667974824475, 0.03449694644815369, 0.036668724852398624, 0.03386133696006163, 0.03450654320904333, 0.0365429187981478, 0.03653849739892468, 0.038486067094720716, 0.03498855809243445, 0.03907534042043383, 0.033102186436615715, 0.04040928074283016, 0.04324156802362537, 0.03596481477570021, 0.028674919556207126, 0.01865422312190713, 0.03794190940530017, 0.040779996444632566, 0.03542361343651772, 0.03530415226266799, 0.041685326779636, 0.0339697219248746, 0.03693553489712513, 0.033350491953205816, 0.03212225091645271, 0.031991239687519955, 0.03501496454157151, 0.03174827220226252, 0.033826001754043156, 0.034611496824858715, 0.03887594332314398, 0.034383224467340594, 0.037607211350583265, 0.03623489800591932, 0.034712619290142986, 0.03856630426736825, 0.04096357343941652, 0.03639492864994826, 0.051019583874626975, 0.02319320164628948, 0.04512278995968238, 0.04532802411689806, 0.0497178445936062, 0.045782721513412124, 0.030694518026976484, 0.040451365523393575, 0.04404588983754496, 0.04532109560352171, 0.05019019863648506, 0.07581954937203722, 0.043933334005391345, 0.06865883560242257, 0.04034218458425705, 0.05352130709136932, 0.037615219362293895, 0.04036831150009972, 0.07875902791709409, 0.0733495226645695, 0.04390412782457906, 0.07581986902559777, 0.06364378177499452]\n",
      "0.050460061525808356\n"
     ]
    }
   ],
   "source": [
    "print(pos_error)\n",
    "\n",
    "print(sum(pos_error)/len(pos_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "e47c399a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.3374520857634875, 1.2694635075395293, 1.2306742123064238, 1.1814288668932114, 0.9739221112876549, 0.8437684607268737, 0.8905598494551664, 1.4879086043413745, 1.0175707541435963, 1.3316623910505876, 1.0758992757172001, 1.0256813925296093, 1.4802466805307068, 0.9986141810823644, 0.5820482121886773, 0.8195736973858024, 1.0806178078285689, 0.9160759366559211, 0.5350723590474957, 0.910410148051961, 0.8977712516439592, 0.8011129983822765, 0.9864315688187442, 0.854974734018214, 0.8247284227633513, 0.7982917489687534, 0.4255038954028892, 0.7566997473190137, 0.7980817000259575, 0.7537491841440337, 0.7350109783757549, 0.6615146368759273, 0.7931336259780188, 0.5948484383363551, 0.692715545026475, 0.6732437198514332, 0.5927274781943047, 0.4330349050609745, 0.6235147980590605, 0.6183444442003915, 0.6104135072955692, 0.5902298693787151, 0.5537264364928144, 0.3178772520901705, 0.5749486875504096, 0.5841698688957861, 0.6226397824333098, 0.48980304527255697, 1.060608435724376, 0.4047784740158338, 0.44591578304158014, 0.816244389894104, 0.8328002044441694, 0.47025712726510355, 0.4575173624968077, 0.501089110432351, 0.4500566413561612, 0.3889937054437693, 0.4862722423439242, 0.46349220163770277, 0.49030469378504493, 0.5116934148804199, 0.45472701996405834, 0.4949926777609427, 0.4612697784619302, 0.41489351197045127, 0.4880904842759157, 0.422371944392783, 0.33104321157001637, 0.48734940856721676, 0.6283055649850515, 0.5898800824219631, 0.34486314535520424, 0.40947020269867834, 0.3774032124758327, 0.3528568928456278, 0.3081574963723737, 0.4065232948040052, 0.376556010509671, 0.4433082125176347, 0.5506484466094517, 0.5211670709494902, 0.5847195379028309, 0.42599020954664146, 0.6511339522657588, 0.4900644130597289, 0.5876142374040978, 0.6045700421007266, 0.5482651546902451, 0.7174799072376777, 0.5503038798523817, 0.5573988392238395, 0.4865827435522364, 0.5902697102538411, 0.544084226995107, 0.655862479791028, 0.5034189918670862, 0.3882293984300372, 0.512102543166623, 0.5265634984656905, 0.5799811455395294, 0.49935266106323506, 0.6123022946769384, 0.5851090480425554, 0.5032469119008617, 1.1181798470590747, 0.5194044911865303, 1.7505857978251038, 0.49374252251570167, 1.7323067979803843, 1.8371936007846228, 1.9614286164391879, 0.7876311273291032, 1.8043187233218736, 1.802551336450252, 1.4526162759830372, 1.6706874615294531]\n",
      "0.7344195443340521\n"
     ]
    }
   ],
   "source": [
    "print(rot_error)\n",
    "\n",
    "print(sum(rot_error)/len(rot_error))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "2a8feb97a30f0c0881f8e9b0bc542abf8861c7a1cbabf22b5193b3eb6b79469f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
