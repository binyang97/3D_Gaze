{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84633162",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import platform\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "from pupil_apriltags import Detector\n",
    "import open3d as o3d\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import collections\n",
    "import k3d\n",
    "from PoseEstimation.Mesh_Matcher import *\n",
    "from PoseEstimation.Colmap_Reader import *\n",
    "from PoseEstimation.Apriltag_Colmap import *\n",
    "from PoseEstimation.GT_Extration import rigid_transform_3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3976cf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "a2d2 = [[-3.738231 ,-0.731755 ,-0.328742],\n",
    "    [-2.637552 ,-0.291120 ,-2.638498],\n",
    "    [0.646090 ,-0.735447 ,-0.999240],\n",
    "    [-0.068454 ,-1.510249 ,2.817723],\n",
    "    [-3.638991 ,-0.949203 ,1.054112],\n",
    "    [-1.450608 ,-0.856347 ,0.655611]]\n",
    "\n",
    "a2d1 = [[-0.463405 ,-0.737901 ,3.250370],\n",
    "       [-2.756239 ,-0.312765 ,2.103297],\n",
    "       [-1.103867 ,-0.729082 ,-1.151607],\n",
    "       [2.675915 ,-1.559122 ,-0.357202],\n",
    "       [0.901114 ,-0.947988 ,3.181215],\n",
    "       [0.618660 ,-0.928016 ,0.953832]]\n",
    "\n",
    "a1d1 = [[3.176764, -0.743093 ,0.347837],\n",
    "       [1.207308 ,-0.537581 ,3.230441],\n",
    "       [-1.180794, -0.635370 ,1.481291],\n",
    "       [-1.357942, -1.557935 ,-0.596481],\n",
    "       [1.503481 ,-1.525294, -3.660501],\n",
    "       [0.554387 ,-0.842245 ,-0.227942]]\n",
    "\n",
    "a1d2 = [[-2.751245, -0.733777 ,-0.333212],\n",
    "       [-0.531045 ,-0.543927 ,-2.986102],\n",
    "       [1.695879 ,-0.656546 ,-0.978193],\n",
    "       [1.536978 ,-1.557403 ,1.012150],\n",
    "       [-1.503375 ,-1.568758 ,3.784639],\n",
    "       [-0.193254 ,-0.846000 ,0.419316]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ead08ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import pi\n",
    "def position_error(T_e, T_gt):\n",
    "\n",
    "    return np.linalg.norm(T_e- T_gt)\n",
    "\n",
    "\n",
    "def rotation_error(R_e, R_gt):\n",
    "    \n",
    "    return (180/pi) * np.arccos((np.trace(np.matmul(R_e, R_gt.T))-1)/2)\n",
    "\n",
    "def draw_registration_result(source, target, transformation, colored = True):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    if colored:\n",
    "        source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "        target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38ac1001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k3d_frustrum(pose, name, size=0.009, color=0x0000ff):\n",
    "    # i.e. not using image sizes \n",
    "    pos = pose[:3, 3]\n",
    "    \n",
    "    forward = -pose[:3, 2] * size * -1.4\n",
    "    right = -pose[:3, 0] * size * 1.25\n",
    "    up = -pose[:3, 1] * size\n",
    "    \n",
    "    #verts = [pos, pos + forward*size ]\n",
    "    verts = [pos, pos + forward - right*0.5 + up*0.5, pos + forward + right * 0.5 + up * 0.5, pos ]\n",
    "    verts += [pos, pos + forward - right*0.5 - up*0.5, pos + forward + right * 0.5 - up * 0.5, pos ]\n",
    "    verts += [pos, pos + forward - right*0.5 + up*0.5, pos + forward - right * 0.5 - up * 0.5, pos]\n",
    "    verts += [pos, pos + forward + right*0.5 + up*0.5, pos + forward + right * 0.5 - up * 0.5, pos]\n",
    "    return k3d.line(verts, color=color, width=2.5, name = name, shader=\"simple\")\n",
    "\n",
    "def visualization_registration(reg, mesh):\n",
    "    vertices = [ ]\n",
    "\n",
    "    frustrums = []\n",
    "\n",
    "    colors = [0xff0000, 0x00ff00, 0x0000ff, 0xffcc00, 0xccff00, 0x00ccff]\n",
    "\n",
    "    for i, frame in enumerate(reg.keys()):\n",
    "        pos = reg[frame][:3, 3] \n",
    "        vertices += pos.tolist()\n",
    "        frustrums.append( k3d_frustrum(reg[frame], name = str(frame), size=0.1, color=colors[i % len(colors)]) )\n",
    "\n",
    "    vertices = np.array(vertices)\n",
    "\n",
    "    lines = k3d.line(vertices, color=0xff0000, width=2.5, shader=\"simple\") # + line\n",
    "    pts = k3d.points(vertices, point_size=0.003)\n",
    "\n",
    "    plot3d = k3d.plot(antialias=True, camera_auto_fit=True)\n",
    "\n",
    "    #plot3d += lines\n",
    "    plot3d += pts \n",
    "\n",
    "    for f in frustrums:\n",
    "        plot3d += f\n",
    "\n",
    "    plot3d += k3d.points( [vertices[:3]], point_size=0.0075, color=0x00ff00)\n",
    "\n",
    "    plot3d += k3d.mesh(np.array(mesh.vertices), np.array(mesh.triangles).flatten(), color=0xffcc00)\n",
    "    plot3d.display()\n",
    "\n",
    "at_detector = Detector(\n",
    "            families=\"tagStandard41h12\",\n",
    "            nthreads=1,\n",
    "            quad_decimate=1.0,\n",
    "            quad_sigma=0.0,\n",
    "            refine_edges=1,\n",
    "            decode_sharpening=0.25,\n",
    "            debug=0,\n",
    "        )\n",
    "\n",
    "\n",
    "Register = collections.namedtuple(\n",
    "    \"RegisterInfo\", [\"CameraPose\", \"Intrinsic\", \"TagPose\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "898bf8c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if platform == \"linux\" or platform == \"linux2\":  \n",
    "# linux\n",
    "    dataset_path = r\"/home/biyang/Documents/3D_Gaze/dataset/PupilInvisible/office1/data_1/images_undistorted_reduced\"\n",
    "    database_path = r\"/home/biyang/Documents/3D_Gaze/dataset/PupilInvisible/office1/data_1/colmap_reconstruction\"\n",
    "    keypoints_gt = np.array(a1d2)\n",
    "elif platform == \"win32\":\n",
    "# Windows...\n",
    "    dataset_path = r\"\"\n",
    "    database_path = r\"\"\n",
    "    \n",
    "VISUALIZATION_3D = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "605973af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected model format: '.bin'\n",
      "Detected model format: '.bin'\n"
     ]
    }
   ],
   "source": [
    "database_colmap = ColmapReader(database_path)\n",
    "cameras, images, points3D = database_colmap.read_sparse_model()\n",
    "pcd_rc, _ = database_colmap.read_dense_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7ac9eff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:180: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are totally 1 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 3 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 2 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "There are totally 1 tags in the frame\n",
      "0.48144402257942437\n",
      "[0] [6] 3\n"
     ]
    }
   ],
   "source": [
    "registered_3d_points_xyz = {} # register for each tag (including only xyz)\n",
    "registered_3d_points_info = {} # register for each tag (including other info)\n",
    "registered_3d_points_repro_error = {} # register for each tag (including other info)\n",
    "visited_id = []\n",
    "for frame in images.values():\n",
    "\n",
    "    img_fullpath = os.path.join(dataset_path, frame.name)\n",
    "    img = cv2.imread(img_fullpath, cv2.IMREAD_GRAYSCALE)\n",
    "    tags = at_detector.detect(img)\n",
    "    if len(tags) == 0:\n",
    "        continue\n",
    "\n",
    "    tag_ids = [tag.tag_id for tag in tags]\n",
    "    masks = get_mask(img_grayscale=img, tags=tags, visualization=False)\n",
    "\n",
    "    # Find the corresponding 3d points\n",
    "    search_space_pixels = np.array(frame.xys.astype(int))\n",
    "    points_3d = frame.point3D_ids\n",
    "    corresponding_3d_ids, _ = get_corresponding_3d_points_ids(masks, search_space_pixels, points_3d)\n",
    "\n",
    "    # filter the duplicated ids\n",
    "    for (tag_id, corresponding_3d_id) in zip(tag_ids, corresponding_3d_ids):\n",
    "        non_visited_3d_id = filter_array(corresponding_3d_id, visited_id)\n",
    "        non_visited_3d_id = list(non_visited_3d_id)\n",
    "        visited_id.extend(non_visited_3d_id)\n",
    "\n",
    "        corresponding_3d_xyz, corresponding_3d_repro_error, corresponding_3d_info = get_valid_3d_points(non_visited_3d_id, points3D)\n",
    "\n",
    "\n",
    "        if len(corresponding_3d_xyz) == 0:\n",
    "            continue\n",
    "        if tag_id not in registered_3d_points_xyz.keys():\n",
    "            registered_3d_points_xyz[tag_id] = corresponding_3d_xyz\n",
    "            registered_3d_points_info[tag_id] = corresponding_3d_info\n",
    "            registered_3d_points_repro_error[tag_id] = corresponding_3d_repro_error\n",
    "\n",
    "        else:\n",
    "            registered_3d_points_xyz[tag_id] = np.concatenate((registered_3d_points_xyz[tag_id], corresponding_3d_xyz), axis=0)\n",
    "            registered_3d_points_info[tag_id] = np.concatenate((registered_3d_points_info[tag_id], corresponding_3d_info), axis=0)\n",
    "            registered_3d_points_repro_error[tag_id] = np.concatenate((registered_3d_points_repro_error[tag_id], corresponding_3d_repro_error), axis=0)\n",
    "\n",
    "\n",
    "# with open(r\"D:\\Documents\\Semester_Project\\3D_Gaze\\dataset\\PupilInvisible\\room1\\apriltags_repro_error.json\", \"w\") as outfile:\n",
    "#    json.dump({k: v.tolist() for k, v in registered_3d_points_repro_error.items()}, outfile, indent=4)\n",
    "\n",
    "filtered_registered_tag_points_xyz, outliers_xyz = filter_registered_points(registered_3d_points_xyz, registered_3d_points_repro_error)\n",
    "\n",
    "keypoints_rc = []\n",
    "for points in filtered_registered_tag_points_xyz.values():\n",
    "    keypoints_rc.append(np.mean(points, axis = 0))\n",
    "keypoints_rc = np.array(keypoints_rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cd8cd76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd_copy = copy.deepcopy(pcd_rc)\n",
    "pcd_rc.paint_uniform_color(np.array([220, 220 ,220])/255)\n",
    "\n",
    "\n",
    "# for tag in registered_3d_points_info.keys():\n",
    "#     for info in registered_3d_points_info[tag]:\n",
    "#         print(info.error)\n",
    "    #visualization_3d(pcd_rc, registered_3d_points_xyz, highlight=False)\n",
    "\n",
    "pcd_outliers = create_pcd(outliers_xyz, color = [0, 0 ,0])\n",
    "vis = [pcd_rc, pcd_outliers]\n",
    "for i, tag_id in enumerate(filtered_registered_tag_points_xyz.keys()):\n",
    "\n",
    "    pcd_tag = create_pcd(filtered_registered_tag_points_xyz[tag_id], colorbar[i])\n",
    "    vis.append(pcd_tag)\n",
    "\n",
    "o3d.visualization.draw_geometries(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "08260df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "std::vector<Eigen::Vector3d> with 12455 elements.\n",
       "Use numpy.asarray() to access data."
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcd_rc.points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "51cec33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keypoints_gt = np.flip(keypoints_gt, 0)\n",
    "keypoints_gt = np.array(a1d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b76cffa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reflection detected\n"
     ]
    }
   ],
   "source": [
    "s_opt, R_opt,t_opt = rigid_transform_3D(np.asmatrix(keypoints_gt), np.asmatrix(keypoints_rc), True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "68882d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "est_extrinsic = np.concatenate(\n",
    "                    [np.concatenate([R_opt, t_opt.reshape(3, 1)], axis=1), np.array([[0, 0, 0, 1]])], axis=0)\n",
    "\n",
    "pcd_gt= o3d.geometry.PointCloud()\n",
    "pcd_gt.points = o3d.utility.Vector3dVector(keypoints_gt)\n",
    "\n",
    "pcd_rc= o3d.geometry.PointCloud()\n",
    "pcd_rc.points = o3d.utility.Vector3dVector(keypoints_rc)\n",
    "\n",
    "pcd_rc.scale(s_opt ,center=np.zeros(3))\n",
    "\n",
    "draw_registration_result(pcd_rc, pcd_gt, est_extrinsic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9aaddf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_error = []\n",
    "rot_error = []\n",
    "for gt_pose, est_pose in zip(GT_CameraPose.values(), IPhone_Registration.values()):\n",
    "    pos_error.append(position_error(est_pose[:3, 3], gt_pose[:3, 3]))\n",
    "    rot_error.append(rotation_error(est_pose[:3, :3], gt_pose[:3, :3]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d607696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4083566926725213, 0.4019291218919338, 0.38849037585498103, 0.3179002427648748, 0.17195424301140128, 0.11458310610614114, 0.14301039197887933, 0.022714978658934494, 0.6297980737814189, 0.6552598802543246, 0.7307978960767659, 0.8091163774747812, 0.8676330072610149, 0.8760745025839376, 0.9575329461968345, 0.9874435095169811, 1.0452871353042466, 1.0755181084883743, 1.1233902567194112, 1.1597960564759109, 0.060254736393963046, 0.0716734155875048, 0.12122319913206606, 0.1498385274470514, 0.16208966344672893, 0.18995614177565434, 0.19998547469113256, 0.20044754530162393, 0.23646957514635358, 2.6106487057365686, 2.619049988957643, 2.6365642349417837, 0.7218254377285517, 0.6183800254919476, 0.39066947748013303, 1.9307558123797426, 0.6714375587603891, 1.709616233650727]\n",
      "0.741775596240085\n"
     ]
    }
   ],
   "source": [
    "print(pos_error)\n",
    "\n",
    "print(sum(pos_error)/len(pos_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e47c399a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.36927478990779, 7.187212157400475, 7.115298311392832, 6.261001362692682, 3.9361325580072655, 1.9489432525297643, 3.2921470266853063, 0.9753621536041962, 10.96642390395527, 10.455888527461664, 8.952275416433888, 7.628594003444916, 7.443266153672563, 8.12870438897756, 7.440157897565868, 7.729102133388627, 8.647531289409653, 7.000740773123268, 8.05635237001087, 9.879733784407085, 1.3850683352572002, 3.1138184356959884, 4.581211794640418, 4.727277382194506, 4.557758585460071, 5.460402817512808, 6.205918044248811, 6.7300659156342375, 7.04010462180643, 90.00804364895187, 90.03090195805373, 90.07239123681987, 11.47318425571363, 11.34330534303244, 11.385697549881717, 13.840148057493119, 7.4777019939761376, 19.630427428189975]\n",
      "13.933620254174592\n"
     ]
    }
   ],
   "source": [
    "print(rot_error)\n",
    "\n",
    "print(sum(rot_error)/len(rot_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "167d6c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_textured = o3d.io.read_triangle_mesh(mesh_fullpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a8ba2c7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\ybMas\\anaconda3\\envs\\apriltag\\lib\\site-packages\\traittypes\\traittypes.py:101: UserWarning: Given trait value dtype \"float64\" does not match required type \"float32\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n",
      "d:\\Users\\ybMas\\anaconda3\\envs\\apriltag\\lib\\site-packages\\traittypes\\traittypes.py:101: UserWarning: Given trait value dtype \"int32\" does not match required type \"uint32\". A coerced copy has been created.\n",
      "  np.dtype(self.dtype).name))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf664837df8245c8a2082d7f2737af61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualization of Camera Pose\n",
    "#visualization_registration(PI_registration, mesh_textured)\n",
    "visualization_registration(GT_CameraPose, mesh_textured)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b10adfcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: Der angeforderte Transformationsvorgang wird nicht unterstützt. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: Das Handle ist ungültig. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: Das Handle ist ungültig. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: Der angeforderte Transformationsvorgang wird nicht unterstützt. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: Das Handle ist ungültig. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: Der angeforderte Transformationsvorgang wird nicht unterstützt. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: Der angeforderte Transformationsvorgang wird nicht unterstützt. \n",
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: Der angeforderte Transformationsvorgang wird nicht unterstützt. \n"
     ]
    }
   ],
   "source": [
    "pcd_sample = mesh_textured.sample_points_uniformly(number_of_points=10000)\n",
    "o3d.visualization.draw_geometries([pcd_sample])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "2a8feb97a30f0c0881f8e9b0bc542abf8861c7a1cbabf22b5193b3eb6b79469f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
